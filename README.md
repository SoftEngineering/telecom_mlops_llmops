# ğŸ“¡ Projeto: Plataforma MLOps + LLMOps para Telecom

**Modelos: Churn Prediction + Assistente LLM Telecom (RAG + AutomaÃ§Ã£o)**
**Stack: Google Cloud + GitHub + GitHub Actions + Vertex AI**

---

## ğŸ§­ VisÃ£o Geral do Projeto

Este repositÃ³rio contÃ©m um projeto completo e integrado de **MLOps** e **LLMOps** utilizando **Google Cloud Platform** como infraestrutura principal.
O projeto simula um cenÃ¡rio real de cliente do setor **TelecomunicaÃ§Ãµes**, incluindo:

* Um **modelo de Machine Learning** para prever **churn** (cancelamento)
* Um **Assistente LLM inteligente para suporte de telecom**, usando RAG, conectores e automaÃ§Ãµes
* Pipelines de CI/CD, deploy automatizado, versionamento, monitoramento e boas prÃ¡ticas

O objetivo Ã© **estudar**, **aprender**, **treinar**, e **reproduzir em ambiente real** prÃ¡ticas de engenharia usadas pelas grandes empresas de tecnologia.

---

# ğŸŒ Arquitetura Geral (Mermaid)

```mermaid
flowchart LR
    DEV["Time de Engenharia ML/LLMOps"] --> GH["GitHub: CÃ³digo, Issues, Kanban"]
    GH --> CI["GitHub Actions: CI/CD"]
    CI --> GCP["Google Cloud Platform"]

    subgraph Dados["Camada de Dados"]
        GCS["Cloud Storage: Data Lake (Raw/Bronze/Silver/Gold)"]
        BQ["BigQuery: DW & Feature Store"]
        GCS --> BQ
    end

    subgraph MLOps["Pipeline MLOps - Modelo de Churn"]
        VPIPE["Vertex AI Pipelines"]
        VTRAIN["Vertex AI Training"]
        VREG["Vertex AI Model Registry"]
        VPRED["Vertex AI Prediction"]
        BQ --> VPIPE
        VPIPE --> VTRAIN --> VREG --> VPRED
    end

    subgraph LLMOps["Pipeline LLMOps - Assistente Telecom"]
        RAG["Vertex AI Search / RAG"]
        LLM["LLM (Gemini / Llama / etc.) via Vertex AI"]
        AGENT["Orquestrador / Agent em Cloud Run"]
        GCS --> RAG
        BQ --> RAG
        RAG --> LLM --> AGENT
    end

    subgraph Runtime["APIs e Consumo"]
        CRUN["Cloud Run: APIs de churn e assistente"]
        CHAT["Canais: Chatbot / WhatsApp / Portal"]
        VPRED --> CRUN
        AGENT --> CRUN
        CHAT --> CRUN
    end

    GCP --- Dados
    GCP --- MLOps
    GCP --- LLMOps
    GCP --- Runtime
```

---

# ğŸ§© Componentes do Projeto

### **1. MLOps â€“ Modelo de Churn**

Inclui:

* IngestÃ£o de dados (BSS, CRM, redes, CSVs)
* Data Lake (GCS)
* Data Warehouse (BigQuery)
* Feature Store (BigQuery)
* Pipeline de treinamento (Vertex Pipelines)
* Versionamento de modelos (Model Registry)
* Deploy Online e Batch (Vertex Predictions)
* Monitoramento de drift, mÃ©tricas e logs

---

### **2. LLMOps â€“ Assistente Inteligente Telecom**

ContÃ©m:

* Base RAG com documentos de telecom (FAQ, manuais, polÃ­ticas internas)

* Embeddings e index via Vertex AI Search

* LLM (Gemini, Llama, Mistral â€“ configurÃ¡vel)

* Orquestrador/Agente em Cloud Run

* Ferramentas (Tools) conectadas ao:

  * Modelo de churn
  * CRM
  * Regras de planos e ofertas
  * DiagnÃ³stico de problemas de internet

* Observabilidade de LLM (logging, safety, evals automÃ¡ticos)

---

### **3. CI/CD â€“ GitHub Actions + Google Cloud**

Inclui:

* ValidaÃ§Ã£o automÃ¡tica de cÃ³digo
* Lint + Testes + Security checks
* Build & push de contÃªineres (Artifact Registry)
* Deploy para Cloud Run
* Update automatizado de pipelines (Vertex AI Pipelines)
* Registro automÃ¡tico de modelos aprovados

---

# ğŸ“‚ Estrutura de Pastas Recomendada

```
telecom-ml-llmops/
â”‚
â”œâ”€â”€ mlops/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ serving/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ llmops/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ tools/
â”‚   â””â”€â”€ evaluations/
â”‚
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ gcloud/
â”‚   â”œâ”€â”€ networks/
â”‚   â””â”€â”€ iam/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample/
â”‚   â””â”€â”€ schemas/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ mlops/
â”‚   â”œâ”€â”€ llmops/
â”‚   â””â”€â”€ api/
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â”œâ”€â”€ ci.yml
        â”œâ”€â”€ cd-ml.yml
        â”œâ”€â”€ cd-llm.yml
        â””â”€â”€ security.yml
```

---

# ğŸš€ Roadmap (6 semanas)

### **Semana 1 â€“ Planejamento**

* Criar repositÃ³rio GitHub
* Configurar Kanban
* Preparar estrutura inicial
* Provisionar Google Cloud

### **Semana 2 â€“ MLOps: dados**

* Criar Data Lake e DW
* Criar features
* Criar pipeline inicial

### **Semana 3 â€“ Treinamento e Deploy do modelo de churn**

* Training pipeline
* AvaliaÃ§Ã£o e registro
* Deploy em Vertex Prediction

### **Semana 4 â€“ LLMOps: RAG**

* IngestÃ£o de documentos
* CriaÃ§Ã£o do Ã­ndice RAG
* Testes iniciais

### **Semana 5 â€“ LLM Assistant**

* Criar agente
* Conectar churn ao LLM
* Criar APIs

### **Semana 6 â€“ CI/CD & Observabilidade**

* GitHub Actions completo
* Alertas e dashboards
* Testes finais

---

# ğŸ§  Caso de Uso Principal (LLM em Telecom)

O projeto implementa um dos casos mais valorizados no mercado atual:

### **Assistente LLM de Suporte TÃ©cnico e RetenÃ§Ã£o para Telecom**

Capaz de:

* Diagnosticar problemas de internet
* Explicar fatura, cobranÃ§as, contratos
* Sugerir upgrades conforme perfil
* Detectar risco de churn via modelo ML
* Registrar atendimentos
* Integrar CRM, billing e regras comerciais

---

# ğŸ›¡ï¸ Boas PrÃ¡ticas de Desenvolvimento

### **OrganizaÃ§Ã£o e Fluxo de Trabalho**

* GitFlow simplificado (main + develop + feature-branches)
* Pull Requests obrigatÃ³rios
* Issues sempre vinculadas a PRs
* DocumentaÃ§Ã£o incremental por PR

---

### **CÃ³digo e Qualidade**

* Linting (flake8, black, isort)
* Testes unitÃ¡rios (pytest)
* Testes E2E para pipelines
* Post-mortems para falhas crÃ­ticas

---

### **Infraestrutura**

* Tudo versionado (IaC â€“ Terraform)
* Sem chaves expostas (OIDC GitHub â†’ GCP)
* Logs e mÃ©tricas obrigatÃ³rios em Cloud Monitoring

---

### **MLOps**

* Feature Store padronizada
* Drift detection ativo
* Versionamento de datasets e modelos
* ComparaÃ§Ã£o de mÃ©tricas para promoÃ§Ã£o de modelos

---

### **LLMOps**

* Prompts versionados em diretÃ³rio dedicado
* Testes de regressÃ£o semÃ¢ntica (Vertex AI Evaluation)
* PolÃ­ticas de seguranÃ§a para LLM (moderaÃ§Ã£o)
* SeparaÃ§Ã£o entre:

  * prompt de sistema
  * prompt de regras
  * prompt de contexto RAG

---

### **DocumentaÃ§Ã£o**

* Toda sprint gera documentaÃ§Ã£o incremental
* Arquitettura â†’ docs/architecture
* Pipelines â†’ docs/mlops e docs/llmops
* APIs â†’ docs/api

---

# ğŸ“ Como Contribuir

1. Criar uma branch:

```
git checkout -b feature/nome-da-feature
```

2. Fazer commits pequenos e claros:

```
git commit -m "feat: adiciona pipeline de treinamento v1"
```

3. Abrir PR vinculada a uma Issue:

* RevisÃ£o entre engenheiros
* Checagens automÃ¡ticas via GitHub Actions

4. Mesclar apenas apÃ³s CI verde

---

# ğŸ“ Contato e Suporte

**Time de Engenharia (SimulaÃ§Ã£o de Cliente Telecom):**

* Engenheiro de Machine Learning
* Engenheiro de LLMOps

---

# ğŸ¯ Objetivo Final do Projeto

Criar uma **plataforma de ML + LLM realmente profissional**, seguindo padrÃµes industriais do Google Cloud, reprodutÃ­vel em qualquer empresa, permitindo:

* Apresentar em portfÃ³lio
* Treinar equipes
* Construir MVPs de IA corporativa

---

